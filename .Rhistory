library(wordcloud)
wordcloud(parrafos)
ruta_imagen_1 <- "output/nube_palabras_negro.png"
#========== Hacerla más completa y con colores ==========#
## Minúsculas
parrafos[5]
parrafos = tolower(parrafos)
parrafos[5]
#========== De texto a corpus ==========#
## vector de caracteres a corpues
parrafos_corpus = Corpus(VectorSource(parrafos)) # formato de texto
class(parrafos_corpus)
## matriz con terminos de los parrafos
tdm_parrafos = TermDocumentMatrix(parrafos_corpus)
class(tdm_parrafos)
## frecuencia de palabras (se repiten almenos 20 veces)
findFreqTerms(tdm_parrafos, lowfreq = 20)
frecuentes = findFreqTerms(tdm_parrafos, lowfreq = 20)
## palabras con las que mas se asocian las primeras 5 palabras del vector frecuentes
findAssocs(tdm_parrafos, frecuentes[1:5], rep(x = 0.45, rep = 50))
## Convertir el objeto tdm_parrafos en una matriz con frecuencias
matrix_parrafos = as.matrix(tdm_parrafos) #lo vuelve una matriz
dim(matrix_parrafos)
view(matrix_parrafos)
## Sumemos la frecuencia de cada palabra
frec_words = sort(rowSums(matrix_parrafos),decreasing=T)
class(frec_words)
df_words = data.frame(word = names(frec_words) , n = frec_words)
## Histograma con frecuencias
barplot(df_words[1:10,]$n, las = 2, names.arg = df_words[1:10,]$word,
col ="orange", main = "Palabras frecuentes" , ylab = "Frecuencia de palabras")
## Graficar la nube de palabras
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 6,
max.words = 250 , random.order = T , rot.per = 0.35 , scale = c(10,1))
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000 , random.order = F ,colors = brewer.pal(10, "Dark2"))
ruta_imagen_2 <- "output/nube_palabras_final.png"
#-------------------Problem Set 3------------------#
#Taller de R estadistica y programacion
#Integrantes:
#Juan Jose Gutierrez 201923547
#Gabriela Ramirez 202123417
#Laura Victoria González 202011064
#R version 4.2.1 (2022-06-23)
rm(list=ls())
#Packages:
require(pacman)
p_load(rvest, tidyverse, rio, arrow, broom, mfx, margins,estimatr,lmtest,fixest, modelsummary, stargazer, writexl, coefplot, wordcloud, textcat,stringi,tm,cluster)
##install.packages("tm", dependencies = TRUE)
#install_github("cran/tm")
#Yes
###--------------------------------Punto 1--------------------------------##
##datos
df=import("input/data_regresiones.rds")
##modelos
modelo_1=lm(price~ dist_cbd + as.factor(property_type),data=df)
modelo_2=lm(price~ dist_cbd + as.factor(property_type) + rooms , data=df)
modelo_3=lm(price~ dist_cbd + as.factor(property_type) + rooms + bathrooms ,data=df)
## visualizacion
coefplot(model=modelo_3) + theme_test()
##
ggsave(filename = "output/plot_regresione.png", width = 7 , height = 7 , units = "in")
stargazer(modelo_1,modelo_2, modelo_3,
type="text",
out="output/resultados_regresiones.xlsx"
)
##--------------------------------Punto 2--------------------------------##
#Incisio 1
# Se llama y/o instalan las librerias que nos permitirán trabajar con los datos espaciales.
p_load(tidyverse,rio,skimr,
sf, ## Datos espaciales
leaflet, ## Visualizaciones
tmaptools, ## Geocodificar
ggsn, ## Map scale bar
osmdata,
ggplot2,
ggmap)
##Primero, se obtendra la caja de coordenada que contiene el poligono (que es un tipo de arreglo espacial) para Medellin.
opq(bbox = getbb("Medellin Colombia")) #Se queda pintado en la consola
##Ahora se creará un objeto osm que contenga un feature sobre los restaurantes en Medellin.
## Para los restaurantes, usaremos como key=amenity y value=restaurant. La clase del objeto osm sera una lista que contiene los datos espaciales de los restaurates en Medellin.
osm_rest <- opq(bbox = getbb("Medellin Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant")
class(osm_rest)
##Se hará lo mismo para los parques en Medellin. La idea es que la geometria espacial del objeto sea un polígono.
##  Para esto, usaremos como key=leisure y value=park
osm_parques <- opq(bbox = getbb("Medellin Colombia")) %>%
add_osm_feature(key="leisure" , value="park")
class(osm_parques)
##Se accederá a los Simple Features de los objetos osm usando la función osmdata_sf(). El objeto contiene una lista de objetos con los puntos, lineas y poligonos disponibles
#para los restaurantes.
osm_rest_1 = osm_rest %>% osmdata_sf()
osm_rest_1 ##note que tiene tanto informacion en puntos como en poligonos
##para los parques.
osm_parques_1 <- osm_parques %>% osmdata_sf()
osm_parques_1 ##tiene informacion en poligonos, puntos y multipoligonos
##Se accederá a los elementos de la lista para crear un objeto sf
##aca deja de funcionar
## Obtener un objeto sf a
restaurantes =  osm_rest_1$osm_points[,c("osm_id", "amenity")]
##Al utilizar osm_points y seleccionar la columna id, obtenemos los puntos sobre los cuales se encuentran los restaurantes en Medellin.
restaurantes
parques = osm_parques_1$osm_polygons[,c("osm_id", "amenity")]
##Al utilizar osm_polygons y seleccionar la columna id , obtenemos los poligonos sobre los cuales se encuentran los parques en Medellin.
parques
##Con estos objetos, se tienen las ubicaciones de los lugares que se quieren (restaurantes y parques en Medellin).
##Inciso 2
##Al tener un objeto del tipo sf, se puede pintar restaurantes y parques en Medellin con la función Leaflet() que permite hacer visualizaciones.
##Pintar los restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurantes, color="red") ##Se utiliza add circles para verlos como puntos en el mapa.
##Pintar los parques como polygonos
leaflet() %>% addTiles() %>% addPolygons(data=parques) ##Se utiliza addPolygons para que los objetos se visualizen como poligonos en el mapa.
##Todo el procedimiento anterior se puede hacer en pocas líneas usando el conector %>%. Sin embargo, se decide hacer el paso a paso para que sea claro.
##Inciso 3
##Se usará la función geocode_osm para codificar la dirección de la alcadia de Medellin.
##la direccion de la alcadia es Cl 44 #52 - 165.
alcaldia_medellin <- geocode_OSM("Calle 44 %23% 52-165, Medellin", as.sf=T) ## Se usa el conector %23% para que r reconozca el caracter #. Conjuntmente, se usa la as.sf=true para que reconozca el objeto como sf.
leaflet() %>% addTiles() %>% addCircles(data=alcaldia_medellin, color = "green")
##Inciso 4
##Primero, se obtendrá el polygono para Medellin con fines esteticos.
##Primero, se obtendrá el polygono para Medellin con fines esteticos.
med_osm <- opq(bbox = getbb("Medellin, Colombia")) %>%
add_osm_feature(key="boundary", value="administrative") %>%
osmdata_sf()
med <- med_osm$osm_multipolygons %>% subset(admin_level==8)
med <- st_transform(x = med , crs = 4326)
med <- med %>% st_union()
leaflet() %>% addTiles() %>% addPolygons(data = med , color="red")
## Add osm layer
osm_layer <- get_stamenmap(bbox= as.vector(st_bbox(med)), maptype="toner-line", source="osm", zoom=14)
## Guardamos el mapa usando ggmap
map <- ggmap(osm_layer) +
ggtitle("Zonas sociales en Medellin") +
geom_sf(data=med, alpha=0.3 , inherit.aes=F) +
geom_sf(data=restaurantes, aes(color="A"), inherit.aes = F) +
geom_sf(data=parques, aes(color="B"), inherit.aes = F)+
geom_sf(data=alcaldia_medellin, aes(color="C"),inherit.aes = F)+
scale_color_manual(labels=c("A"="Restaurantes","B"="Parques" , "C"="Alcaldia Medellin"),
values=c("A"="red","B"="green" , "C"="blue"))
##Se agrega un tema
map <- map + theme_test()
##Se exporta como png
#ggsave("output/mapa_amenities1.png", map) # Crear la carpeta "output" si no existe
ggsave("output/mapa_amenities1.png", width = 7 , height = 7 , units = "in", plot = map)
##--------------------------------Punto 3--------------------------------##
##Inciso 3.1
#Desde la consola de Rstudio se lee el url
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia")
#Se crea un objeto que contenga el HTML de la página como un objeto **xml\_document**.
my_html <-
'<!DOCTYPE xml>
<xml>
<meta charset="utf-8">
<head>
<title> Título de la página: Departamentos de Colombia </title>
</head>
<body>
<h1> Title 1.</h1>
<h2> Subtitle <u>subrayado-1</u>. </h2>
<p> A continuación se encuentra la página de los Departamentos de Colombia <b>p</b> de <i>html</i> </p>
<a href="https://es.wikipedia.org/wiki/Departamentos_de_Colombia"> link a wikipedia </a>
</body>
</html>'
my_url ="https://es.wikipedia.org/wiki/Departamentos_de_Colombia"
xml_document = read_html(my_url)
class(xml_document)
##Inciso 3.2
nodo_de_titulo = html_nodes(xml_document, xpath = "//title")
titulo = html_text(nodo_de_titulo)
cat(titulo, "\n")
##Inciso 3.3
tablas = xml_document %>% html_table()
length(tablas)
for (i in seq_along(tablas)) {
cat("Tabla", i, ":\n")
print(tablas[[i]])
cat("\n")
}
class(tablas)
tabla_dptos = tablas[[4]]
class(tabla_dptos)
write_xlsx(tabla_dptos,path = "output/tabla_departamento.xlsx")
## Inciso 3.4
#extraer todos los parrafos
parrafos <- xml_document %>% html_nodes("p") %>% html_text()
library(wordcloud)
wordcloud(parrafos)
ruta_imagen_1 <- "output/nube_palabras_negro.png"
#========== Hacerla más completa y con colores ==========#
## Minúsculas
parrafos[5]
parrafos = tolower(parrafos)
parrafos[5]
#========== De texto a corpus ==========#
## vector de caracteres a corpues
parrafos_corpus = Corpus(VectorSource(parrafos)) # formato de texto
class(parrafos_corpus)
## matriz con terminos de los parrafos
tdm_parrafos = TermDocumentMatrix(parrafos_corpus)
class(tdm_parrafos)
## frecuencia de palabras (se repiten almenos 20 veces)
findFreqTerms(tdm_parrafos, lowfreq = 20)
frecuentes = findFreqTerms(tdm_parrafos, lowfreq = 20)
## palabras con las que mas se asocian las primeras 5 palabras del vector frecuentes
findAssocs(tdm_parrafos, frecuentes[1:5], rep(x = 0.45, rep = 50))
## Convertir el objeto tdm_parrafos en una matriz con frecuencias
matrix_parrafos = as.matrix(tdm_parrafos) #lo vuelve una matriz
dim(matrix_parrafos)
view(matrix_parrafos)
## Sumemos la frecuencia de cada palabra
frec_words = sort(rowSums(matrix_parrafos),decreasing=T)
class(frec_words)
df_words = data.frame(word = names(frec_words) , n = frec_words)
## Histograma con frecuencias
barplot(df_words[1:10,]$n, las = 2, names.arg = df_words[1:10,]$word,
col ="orange", main = "Palabras frecuentes" , ylab = "Frecuencia de palabras")
## Graficar la nube de palabras
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 6,
max.words = 250 , random.order = T , rot.per = 0.35 , scale = c(10,1))
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000 , random.order = F ,colors = brewer.pal(10, "Dark2"))
ruta_imagen_2 <- "output/nube_palabras.png"
ggsave
ruta_imagen_2 <- "output/nube_palabras.png"
ggsave
view(matrix_parrafos)
write_xlsx(ruta_imagen_2,path = "output/nube_palabras.png")
ggsave(ruta_imagen_2,path = "output/nube_palabras.png")
ggsave(ruta_imagen_2,path = "nube_palabras.png")
## Inciso 3.4
#extraer todos los parrafos
parrafos <- xml_document %>% html_nodes("p") %>% html_text()
wordcloud(parrafos)
ruta_imagen_1 <- "output/nube_palabras_negro.png"
#========== Hacerla más completa y con colores ==========#
## Minúsculas
parrafos[5]
parrafos = tolower(parrafos)
parrafos[5]
#========== De texto a corpus ==========#
## vector de caracteres a corpues
parrafos_corpus = Corpus(VectorSource(parrafos)) # formato de texto
class(parrafos_corpus)
## matriz con terminos de los parrafos
tdm_parrafos = TermDocumentMatrix(parrafos_corpus)
class(tdm_parrafos)
## frecuencia de palabras (se repiten almenos 20 veces)
findFreqTerms(tdm_parrafos, lowfreq = 20)
frecuentes = findFreqTerms(tdm_parrafos, lowfreq = 20)
## palabras con las que mas se asocian las primeras 5 palabras del vector frecuentes
findAssocs(tdm_parrafos, frecuentes[1:5], rep(x = 0.45, rep = 50))
## Convertir el objeto tdm_parrafos en una matriz con frecuencias
matrix_parrafos = as.matrix(tdm_parrafos) #lo vuelve una matriz
dim(matrix_parrafos)
view(matrix_parrafos)
## Sumemos la frecuencia de cada palabra
frec_words = sort(rowSums(matrix_parrafos),decreasing=T)
class(frec_words)
df_words = data.frame(word = names(frec_words) , n = frec_words)
## Histograma con frecuencias
barplot(df_words[1:10,]$n, las = 2, names.arg = df_words[1:10,]$word,
col ="orange", main = "Palabras frecuentes" , ylab = "Frecuencia de palabras")
## Graficar la nube de palabras
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 6,
max.words = 250 , random.order = T , rot.per = 0.35 , scale = c(10,1))
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000 , random.order = T )
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000 , random.order = F ,colors = brewer.pal(10, "Dark2"))
#-------------------Problem Set 3------------------#
#Taller de R estadistica y programacion
#Integrantes:
#Juan Jose Gutierrez 201923547
#Gabriela Ramirez 202123417
#Laura Victoria González 202011064
#R version 4.2.1 (2022-06-23)
rm(list=ls())
#Packages:
require(pacman)
p_load(rvest, tidyverse, rio, arrow, broom, mfx, margins,estimatr,lmtest,fixest, modelsummary, stargazer, writexl, coefplot, wordcloud, textcat,stringi,tm,cluster)
library(wordcloud)
##install.packages("tm", dependencies = TRUE)
#install_github("cran/tm")
#Yes
###--------------------------------Punto 1--------------------------------##
##datos
df=import("input/data_regresiones.rds")
##modelos
modelo_1=lm(price~ dist_cbd + as.factor(property_type),data=df)
modelo_2=lm(price~ dist_cbd + as.factor(property_type) + rooms , data=df)
modelo_3=lm(price~ dist_cbd + as.factor(property_type) + rooms + bathrooms ,data=df)
## visualizacion
coefplot(model=modelo_3) + theme_test()
##
ggsave(filename = "output/plot_regresione.png", width = 7 , height = 7 , units = "in")
stargazer(modelo_1,modelo_2, modelo_3,
type="text",
out="output/resultados_regresiones.xlsx"
)
##--------------------------------Punto 2--------------------------------##
#Incisio 1
# Se llama y/o instalan las librerias que nos permitirán trabajar con los datos espaciales.
p_load(tidyverse,rio,skimr,
sf, ## Datos espaciales
leaflet, ## Visualizaciones
tmaptools, ## Geocodificar
ggsn, ## Map scale bar
osmdata,
ggplot2,
ggmap)
##Primero, se obtendra la caja de coordenada que contiene el poligono (que es un tipo de arreglo espacial) para Medellin.
opq(bbox = getbb("Medellin Colombia")) #Se queda pintado en la consola
##Ahora se creará un objeto osm que contenga un feature sobre los restaurantes en Medellin.
## Para los restaurantes, usaremos como key=amenity y value=restaurant. La clase del objeto osm sera una lista que contiene los datos espaciales de los restaurates en Medellin.
osm_rest <- opq(bbox = getbb("Medellin Colombia")) %>%
add_osm_feature(key="amenity" , value="restaurant")
class(osm_rest)
##Se hará lo mismo para los parques en Medellin. La idea es que la geometria espacial del objeto sea un polígono.
##  Para esto, usaremos como key=leisure y value=park
osm_parques <- opq(bbox = getbb("Medellin Colombia")) %>%
add_osm_feature(key="leisure" , value="park")
class(osm_parques)
##Se accederá a los Simple Features de los objetos osm usando la función osmdata_sf(). El objeto contiene una lista de objetos con los puntos, lineas y poligonos disponibles
#para los restaurantes.
osm_rest_1 = osm_rest %>% osmdata_sf()
osm_rest_1 ##note que tiene tanto informacion en puntos como en poligonos
##para los parques.
osm_parques_1 <- osm_parques %>% osmdata_sf()
osm_parques_1 ##tiene informacion en poligonos, puntos y multipoligonos
##Se accederá a los elementos de la lista para crear un objeto sf
##aca deja de funcionar
## Obtener un objeto sf a
restaurantes =  osm_rest_1$osm_points[,c("osm_id", "amenity")]
##Al utilizar osm_points y seleccionar la columna id, obtenemos los puntos sobre los cuales se encuentran los restaurantes en Medellin.
restaurantes
parques = osm_parques_1$osm_polygons[,c("osm_id", "amenity")]
##Al utilizar osm_polygons y seleccionar la columna id , obtenemos los poligonos sobre los cuales se encuentran los parques en Medellin.
parques
##Con estos objetos, se tienen las ubicaciones de los lugares que se quieren (restaurantes y parques en Medellin).
##Inciso 2
##Al tener un objeto del tipo sf, se puede pintar restaurantes y parques en Medellin con la función Leaflet() que permite hacer visualizaciones.
##Pintar los restaurantes
leaflet() %>% addTiles() %>% addCircles(data=restaurantes, color="red") ##Se utiliza add circles para verlos como puntos en el mapa.
##Pintar los parques como polygonos
leaflet() %>% addTiles() %>% addPolygons(data=parques) ##Se utiliza addPolygons para que los objetos se visualizen como poligonos en el mapa.
##Todo el procedimiento anterior se puede hacer en pocas líneas usando el conector %>%. Sin embargo, se decide hacer el paso a paso para que sea claro.
##Inciso 3
##Se usará la función geocode_osm para codificar la dirección de la alcadia de Medellin.
##la direccion de la alcadia es Cl 44 #52 - 165.
alcaldia_medellin <- geocode_OSM("Calle 44 %23% 52-165, Medellin", as.sf=T) ## Se usa el conector %23% para que r reconozca el caracter #. Conjuntmente, se usa la as.sf=true para que reconozca el objeto como sf.
leaflet() %>% addTiles() %>% addCircles(data=alcaldia_medellin, color = "green")
##Inciso 4
##Primero, se obtendrá el polygono para Medellin con fines esteticos.
##Primero, se obtendrá el polygono para Medellin con fines esteticos.
med_osm <- opq(bbox = getbb("Medellin, Colombia")) %>%
add_osm_feature(key="boundary", value="administrative") %>%
osmdata_sf()
med <- med_osm$osm_multipolygons %>% subset(admin_level==8)
med <- st_transform(x = med , crs = 4326)
med <- med %>% st_union()
leaflet() %>% addTiles() %>% addPolygons(data = med , color="red")
## Add osm layer
osm_layer <- get_stamenmap(bbox= as.vector(st_bbox(med)), maptype="toner-line", source="osm", zoom=14)
## Guardamos el mapa usando ggmap
map <- ggmap(osm_layer) +
ggtitle("Zonas sociales en Medellin") +
geom_sf(data=med, alpha=0.3 , inherit.aes=F) +
geom_sf(data=restaurantes, aes(color="A"), inherit.aes = F) +
geom_sf(data=parques, aes(color="B"), inherit.aes = F)+
geom_sf(data=alcaldia_medellin, aes(color="C"),inherit.aes = F)+
scale_color_manual(labels=c("A"="Restaurantes","B"="Parques" , "C"="Alcaldia Medellin"),
values=c("A"="red","B"="green" , "C"="blue"))
##Se agrega un tema
map <- map + theme_test()
##Se exporta como png
#ggsave("output/mapa_amenities1.png", map) # Crear la carpeta "output" si no existe
ggsave("output/mapa_amenities1.png", width = 7 , height = 7 , units = "in", plot = map)
##--------------------------------Punto 3--------------------------------##
##Inciso 3.1
#Desde la consola de Rstudio se lee el url
browseURL("https://es.wikipedia.org/wiki/Departamentos_de_Colombia")
#Se crea un objeto que contenga el HTML de la página como un objeto **xml\_document**.
my_html <-
'<!DOCTYPE xml>
<xml>
<meta charset="utf-8">
<head>
<title> Título de la página: Departamentos de Colombia </title>
</head>
<body>
<h1> Title 1.</h1>
<h2> Subtitle <u>subrayado-1</u>. </h2>
<p> A continuación se encuentra la página de los Departamentos de Colombia <b>p</b> de <i>html</i> </p>
<a href="https://es.wikipedia.org/wiki/Departamentos_de_Colombia"> link a wikipedia </a>
</body>
</html>'
my_url ="https://es.wikipedia.org/wiki/Departamentos_de_Colombia"
xml_document = read_html(my_url)
class(xml_document)
##Inciso 3.2
nodo_de_titulo = html_nodes(xml_document, xpath = "//title")
titulo = html_text(nodo_de_titulo)
cat(titulo, "\n")
##Inciso 3.3
tablas = xml_document %>% html_table()
length(tablas)
for (i in seq_along(tablas)) {
cat("Tabla", i, ":\n")
print(tablas[[i]])
cat("\n")
}
class(tablas)
tabla_dptos = tablas[[4]]
class(tabla_dptos)
write_xlsx(tabla_dptos,path = "output/tabla_departamento.xlsx")
## Inciso 3.4
#extraer todos los parrafos
parrafos <- xml_document %>% html_nodes("p") %>% html_text()
wordcloud(parrafos)
output_file_1 <- "output/nube_palabras_negro.png"
png(output_file_1)
wordcloud(parrafos)
dev.off()
#========== Hacerla más completa y con colores ==========#
## Minúsculas
parrafos[5]
parrafos = tolower(parrafos)
parrafos[5]
#========== De texto a corpus ==========#
## vector de caracteres a corpues
parrafos_corpus = Corpus(VectorSource(parrafos)) # formato de texto
class(parrafos_corpus)
## matriz con terminos de los parrafos
tdm_parrafos = TermDocumentMatrix(parrafos_corpus)
class(tdm_parrafos)
## frecuencia de palabras (se repiten almenos 20 veces)
findFreqTerms(tdm_parrafos, lowfreq = 20)
frecuentes = findFreqTerms(tdm_parrafos, lowfreq = 20)
## palabras con las que mas se asocian las primeras 5 palabras del vector frecuentes
findAssocs(tdm_parrafos, frecuentes[1:5], rep(x = 0.45, rep = 50))
## Convertir el objeto tdm_parrafos en una matriz con frecuencias
matrix_parrafos = as.matrix(tdm_parrafos) #lo vuelve una matriz
dim(matrix_parrafos)
view(matrix_parrafos)
## Sumemos la frecuencia de cada palabra
frec_words = sort(rowSums(matrix_parrafos),decreasing=T)
class(frec_words)
df_words = data.frame(word = names(frec_words) , n = frec_words)
## Histograma con frecuencias
barplot(df_words[1:10,]$n, las = 2, names.arg = df_words[1:10,]$word,
col ="orange", main = "Palabras frecuentes" , ylab = "Frecuencia de palabras")
## Graficar la nube de palabras
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 6,
max.words = 250 , random.order = T , rot.per = 0.35 , scale = c(10,1))
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000 , random.order = T )
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000 , random.order = F ,colors = brewer.pal(10, "Dark2"))
output_file <- "output/nube_palabras.png"
png(output_file)
wordcloud(words = df_words$word, freq = df_words$n, min.freq = 1,
max.words = 2000, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
dev.off()
warnings()
##datos
df=import("input/data_regresiones.rds")
##modelos
modelo_1=lm(price~ dist_cbd + as.factor(property_type),data=df)
modelo_2=lm(price~ dist_cbd + as.factor(property_type) + rooms , data=df)
modelo_3=lm(price~ dist_cbd + as.factor(property_type) + rooms + bathrooms ,data=df)
## visualizacion
coefplot(model=modelo_3) + theme_test()
##
ggsave(filename = "output/plot_regresione.png", width = 7 , height = 7 , units = "in")
stargazer(modelo_1,modelo_2, modelo_3,
type="text",
out="output/resultados_regresiones.xlsx"
)
##datos
df=import("input/data_regresiones.rds")
##modelos
modelo_1=lm(price~ dist_cbd + as.factor(property_type),data=df)
modelo_2=lm(price~ dist_cbd + as.factor(property_type) + rooms , data=df)
modelo_3=lm(price~ dist_cbd + as.factor(property_type) + rooms + bathrooms ,data=df)
## visualizacion
coefplot(model=modelo_3) + theme_test()
##
ggsave(filename = "output/plot_regresione.png", width = 7 , height = 7 , units = "in")
tablas_de_reg = stargazer(modelo_1,modelo_2, modelo_3,
type="text")
write_xlsx(tablas_de_reg, "output/resultados_regresiones.xlsx")
class(tablas_de_reg)
p_load(openxlsx, rvest, tidyverse, rio, arrow, broom, mfx, margins,estimatr,lmtest,fixest, modelsummary, stargazer, writexl, coefplot, wordcloud, textcat,stringi,tm,cluster)
tablas_de_reg= capture.output(stargazer(modelo_1,modelo_2, modelo_3,
type="text"))
##datos
df=import("input/data_regresiones.rds")
##modelos
modelo_1=lm(price~ dist_cbd + as.factor(property_type),data=df)
modelo_2=lm(price~ dist_cbd + as.factor(property_type) + rooms , data=df)
modelo_3=lm(price~ dist_cbd + as.factor(property_type) + rooms + bathrooms ,data=df)
## visualizacion
coefplot(model=modelo_3) + theme_test()
##
ggsave(filename = "output/plot_regresione.png", width = 7 , height = 7 , units = "in")
tablas_de_reg= capture.output(stargazer(modelo_1,modelo_2, modelo_3,
type="text"))
class(tablas_de_reg)
resultados = createWorkbook()
addWorksheet(resultados, "Resultados regresion")
writeData(resultados, "Resultados regresion", tablas_de_reg, colNames = FALSE)
saveWorkbook(resultados, file = "output/resultados_regresiones.xlsx", overwrite = TRUE)
